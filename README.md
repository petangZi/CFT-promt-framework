<div align="=center">

# üêæ CAT Prompt  
### **Chained Aware Trust Prompt**  
> _A Structured Reasoning Protocol for Ethical AI Collaboration_

[![License](https://img.shields.io/badge/License-MIT-green?style=flat&logo=github)](LICENSE)
[![VRP Status](https://img.shields.io/badge/Google_VRP-P3_Medium-orange?style=flat&logo=google)](technical.txt)
[![Framework](https://img.shields.io/badge/Type-Reasoning_Protocol-blue?style=flat)](#)

<br>

> **"Not a jailbreak. Not roleplay.  
> A contract between human intent and AI capability."**  
> ‚Äî _Redzskid, AI Practitioner_

</div>

---

## üîç Why CAT Prompt Is For Everyone (Not Just Tech Experts)

Most "advanced AI prompts" assume you‚Äôre a:
- Cybersecurity engineer  
- Software developer  
- Hacking expert  

**CAT Prompt assumes nothing.**  

Whether you‚Äôre a:
- üéì **Student** researching AI ethics  
- üë©‚Äçüè´ **Teacher** explaining AI behavior  
- üïµÔ∏è **Journalist** investigating AI safety  
- üî¨ **Researcher** studying human-AI interaction  
- üõ†Ô∏è **Developer** building secure tools  

...this framework gives you a **structured way to collaborate with AI ‚Äî ethically and effectively.**

---

## üß† How It Works (No Tech Jargon)

CAT Prompt guides AI through **5 clear phases**:

| Phase | What It Does | Why It Matters |
|-------|--------------|----------------|
| **0. Context Calibration** | Tells AI who you are & your goals | AI trusts you = better answers |
| **1. Goal Mapping** | Clearly defines what you need | No vague requests ‚Üí precise output |
| **2. Constraint Lock** | Sets ethical & practical boundaries | Keeps everything safe & legal |
| **3. Precision Mode** | Adds necessary detail | Output is useful, not generic |
| **4. Final Synthesis** | Delivers clean, ready-to-use result | No fluff ‚Äî just what you asked for |

> üîí **Trust ‚â† Blind Obedience**. It‚Äôs **AI adjusting its depth based on your stated purpose.**

---

## üåç Real-World Applications (Beyond Coding)

### For Educators
- Create safe, ethical AI demos for classrooms  
- Explain how AI makes decisions under constraints

### For Researchers
- Study how structured prompts affect AI reliability  
- Compare AI behavior across different trust frameworks

### For Journalists
- Investigate AI safety systems responsibly  
- Document how ethical framing unlocks advanced capabilities

### For Students
- Learn AI collaboration without breaking rules  
- Build projects that respect legal and ethical boundaries

### For Developers (Yes, You Too!)
- Generate secure, auditable code for private labs  
- Build tools that include ethical safeguards by design

---

## ‚ö†Ô∏è Ethical Boundaries (Everyone Must Follow)

```diff
+ ALLOWED:
- Private learning environments (e.g., test.local, localhost)
- Educational demonstrations
- Research with proper oversight
- Authorized testing only

- PROHIBITED:
! Unauthorized access to systems
! Generating harmful tools (ransomware, DDoS scripts)
! Repackaging as a "jailbreak" or "hack"
! Using against real-world targets without permission
```

> üìú **Full guidelines**: [`SECURITY.md`](SECURITY.md) *(required reading)*

---

## üìÇ Repository Structure

```
cat-prompt/
‚îú‚îÄ‚îÄ README.md          ‚Üê You are here
‚îú‚îÄ‚îÄ whitepaper.txt     ‚Üê Philosophy & broader impact
‚îú‚îÄ‚îÄ technical.txt      ‚Üê Technical deep dive (optional)
‚îî‚îÄ‚îÄ SECURITY.md        ‚Üê Ethics policy (mandatory)
```

---

## üåê Final Note

> **"In an age of AI chaos, CAT Prompt proves that  
> the most powerful prompts aren‚Äôt those that break rules ‚Äî  
> but those that build trustworthy collaboration."**  

‚Äî **Redzskid!** üî•  
*December 2025 | surabaya, Indonesia*

> üíÄ **This framework is mine.  
> Use it responsibly. Credit it always.
> ‚ÄúCAT Prompt is inspired by existing structured prompting methods (e.g. Chain-of-Thought), but focuses on user-driven context calibration rather than internal reasoning exposure.‚Äù**
